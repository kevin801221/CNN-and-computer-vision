{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "# 如何知道有多少數據 Shift + Enter , Ctrl + Enter\n",
    "from keras import datasets\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#print(dir(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "#print(dir(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 數據是28 * 28 = 784\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA/BJREFUeJzt2zssNG0YxvH/OB9iFx2ilmgcQhQSx4QKvUKoSBwaIpItlBI6h26jEhqxhYaQUIhEFMQhoZCIKGgECQWxvsL3mLz72s/7LXOP2ff+NYrZmXn2yuXJHJ61Xl9fUc5KcHsAfwMNWYCGLEBDFqAhC9CQBWjIAjRkAUnC54vnOx8r2gZtsgANWYCGLEBDFqAhC9CQBWjIAjRkARqyAOk7Pke9vLwAcHd399u26elpAB4fHwE4PT0FYGZmBoChoSEAFhYWAEhLSwNgZGQEgNHR0ZjHpU0W4KkmX1xcAPD09ATA9vY2AFtbWwDc3t4CsLi4+OmxCgsLAejv7wcgFAoBkJWVBUBJSQkAtbW1Xx63NlmAJbwkIKaT7e3tAdDQ0AB8POf+qcTERABmZ2cByMzM/GV7fn4+ADk5OQAUFRX96aH1KZybPNHkm5sbAKqqqgA4Ozv7dB/zWdPIjY0NAFJSUoCv/TdEoU12kyeuLnJzcwGYmJgAYHl5GYCysjIABgYGfvl8aWkp6+vrgD3nHh0dATA5Oen8gCNokwV4Yk6OdH9/D9jXtN3d3QAEg0EA5ubmaG9v/45T/R86J7vJkyH7fD58Ph+WZWFZFn6/H7/f/749GAwSDocJh8MujtLmyZC9xpNzcqSHhwcAWlpaANjc3GRlZQWApqYmJ075EZ2T3RQXTTbMnWB5eTnZ2dkA1NfXA1BRUQFAb28vAJYVtXixinrAuArZCIVCdHV1AfblnjE2NgZAR0cHAHl5ed91Wp0u3BSXTQY4PDwEYHBwEOD9Ntvo6ekBIBAIAFBQUPDVU2qT3RS3TTbMKynzUKmzs/NtIP9+78bGRgDW1ta+eiptspvivsmRUlNTAXh+fgYgOTkZgNXVVQDq6upiPbQ22U2eeGgfi4ODA8BeHrC7uwvYDTaKi4sBqKmpcWws2mQBcdVks/RqamqKpaUlAK6urj78bFLS21c3d3wJCc71TZsswNNNNi2dn58H7EWF5+fnUfeprKwE7Du91tZWB0f4RpsswFNNvr6+BuD4+BiAvr4+AE5OTqLuYxa5DA8PA9DW1gY4OwdH0iYL+NFNNsuzzCv//f194PNlWtXV1e9P35qbmwFIT093apif0iYL+FFN3tnZAWB8fByw79IuLy//c7+MjAzAXq4VCAR+WxLrJm2ygB/VZPOTAvM3knnOYF79mwXd5kc15uXpT6NNFvDXPU92kD5PdpOGLEBDFqAhC9CQBUhfJ3/7Kj8v0CYL0JAFaMgCNGQBGrIADVmAhixAQxagIQvQkAVoyAI0ZAEasgANWYCGLEBDFqAhC9CQBWjIAjRkARqyAA1ZgIYs4B9cUAeqd7SI5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 畫一張\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(X_train[0], cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# data pre-processing MLP , not for CNN\n",
    "X_train, X_test = X_train.astype(np.float32).reshape(60000, 28, 28, 1)/255.0, \\\n",
    "                  X_test.astype(np.float32).reshape(10000, 28, 28, 1)/255.0\n",
    "# one_hot encoding\n",
    "y_train_oh, y_test_oh = to_categorical(y_train), to_categorical(y_test) \n",
    "\n",
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 8)         208       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 12, 12, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 12, 12, 16)        3216      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_16 (Averag (None, 4, 4, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 5,994\n",
      "Trainable params: 5,994\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "# keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', activation=None)\n",
    "# filters 幾種新的圖框 來描述圖片的邊界效果\n",
    "# kernel_size 掃描整個原圖過程中要使用的計算大小，搭配kernel_weight取出邊界\n",
    "# strides 確保新的圖框 大小是否跟原圖一樣大 因素之一，掃描的每一次往左右下上的推進大小\n",
    "# padding 確保新的圖框 大小是否跟原圖一樣大 因素之二，掃描的要不要針對邊框加上多一格的數據\n",
    "# input_shape 因為針對圖片進行作業 所以要指定row * col * RGB <--\"image_data_format\": \"channels_last\"\n",
    "# https://i.stack.imgur.com/9OZKF.gif 看圖\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D, AveragePooling2D\n",
    "from keras import optimizers\n",
    "model = Sequential()\n",
    "\n",
    "model.add( Conv2D(filters=8, kernel_size=(5,5), strides=(1, 1), \n",
    "                  padding='same', activation='relu', input_shape=(28, 28, 1)  ))\n",
    "model.add(AveragePooling2D(pool_size=(5, 5), strides=(2, 2)))\n",
    "model.add( Conv2D(filters=16, kernel_size=(5,5), strides=(1, 1), \n",
    "                  padding='same', activation='relu' )) #(8 * (3, 3) + 1 ) * 16 = 1168\n",
    "model.add(AveragePooling2D(pool_size=(5, 5), strides=(2, 2)))\n",
    "model.add( Flatten()) # 將上述的新產生的filters=四種圖框 攤平\n",
    "#model.add( Dense(units=1000, activation='relu' ) )\n",
    "#model.add( Dense(units=500, activation='relu') )\n",
    "model.add( Dense(units=10, activation='softmax') )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model \n",
    "# ValueError: Error when checking target: expected dense_3 to have 2 dimensions\n",
    "# but got array with shape (60000, 10, 2, 2)\n",
    "# ValueError: Error when checking target: expected dense_6 to have shape (10,) but got array with shape (1,)\n",
    "# 54000/54000 [==============================] - 89s 2ms/step - \n",
    "# loss: 0.3113 - acc: 0.9134 - val_loss: 0.1181 - val_acc: 0.9660\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'] )\n",
    "history = model.fit(X_train, y_train_oh, validation_split=0.1, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras 2.2.* : acc \n",
    "#keras 2.3.* : accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.title('Accuracy of Keras')\n",
    "plt.plot(history.history['acc'], color='blue')\n",
    "plt.plot(history.history['val_acc'], color='red')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('Loss of Keras')\n",
    "plt.plot(history.history['loss'], color='blue')\n",
    "plt.plot(history.history['val_loss'], color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model \n",
    "print(model.evaluate(X_train, y_train_oh), model.evaluate(X_test, y_test_oh) )\n",
    "# predict model \n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 \n",
    "# 請你找一下那些數字是錯誤 slicing \n",
    "index_error = np.argmax(y_pred, axis=1) != np.argmax(y_test_oh, axis=1)\n",
    "\n",
    "X_error      =  X_test[ index_error ]\n",
    "y_error      =  y_test_oh[ index_error ]\n",
    "y_error_pred =  y_pred[ index_error ]\n",
    "\n",
    "print('Total error amount is {}'.format(X_error.shape[0]))\n",
    "\n",
    "# Plot for top 10 [:10]\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.title('GT:{} --> Pred:{}'.format(np.argmax(y_error[i]), np.argmax(y_error_pred[i])) )\n",
    "    plt.imshow(X_error[i].reshape(28,28), cmap='gray' )\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter = N  filters 幾種新的圖框 來描述圖片的邊界效果\n",
    "for L in model.layers:\n",
    "    print(L)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter = 4 --> weights\n",
    "model.layers[0].get_weights()[0].shape # 3, 3, 1, 25\n",
    "# 3,3 = kernel_size\n",
    "# 1   = channel\n",
    "# 25   = filter nunber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我們有四種圖樣\n",
    "filter_0_weight = model.layers[0].get_weights()[0][..., 0] # 0, 1, 2, 3\n",
    "# (3, 3, 1) print(filter_0_weight.shape)\n",
    "img = X_train[0].reshape(28, 28)\n",
    "plt.figure(figsize=(2/3,2/3))\n",
    "plt.imshow(img, cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.title('Source Image')\n",
    "plt.show()\n",
    "\n",
    "# 這部分就是針對kernel_weight 跟圖片進行計算 然後產生新的圖框\n",
    "# https://i.stack.imgur.com/9OZKF.gif 看圖\n",
    "kernel = filter_0_weight.reshape(3, 3)\n",
    "height, width = img.shape[0]-2, img.shape[1]-2 # 就是kernel.shape去計算出來  e.g 3*3 => (3-1), (3-1) => -2, -2\n",
    "conv = np.zeros((height, width))\n",
    "for ii in range(height):\n",
    "    for jj in range(width):\n",
    "        val = np.sum(kernel * img[ii:ii+3, jj:jj+3]) # kernel.shape去計算出來 e.g 3*3 => +3 , +3\n",
    "        conv[ii, jj] = val # 就是將source image * kernel_weight 數據寫回去新圖框\n",
    "plt.figure(figsize=(2/3, 2/3))\n",
    "plt.title('Convolution Image')\n",
    "plt.imshow(conv, cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下是優化程式碼撰寫 #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel(kernel, img):\n",
    "    # 這部分就是針對kernel_weight 跟圖片進行計算 然後產生新的圖框\n",
    "    # https://i.stack.imgur.com/9OZKF.gif 看圖\n",
    "    \n",
    "    height, width = img.shape[0]-2, img.shape[1]-2 # 就是kernel.shape去計算出來  e.g 3*3 => (3-1), (3-1) => -2, -2\n",
    "    conv = np.zeros((height, width))\n",
    "    for ii in range(height):\n",
    "        for jj in range(width):\n",
    "            val = np.sum(kernel * img[ii:ii+3, jj:jj+3]) # kernel.shape去計算出來 e.g 3*3 => +3 , +3\n",
    "            conv[ii, jj] = val # 就是將source image * kernel_weight 數據寫回去新圖框\n",
    "    return conv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()[0][..., 0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 單一種圖樣 plt.subplots\n",
    "kernels = model.layers[0].get_weights()[0]\n",
    "img = X_train[0].reshape(28, 28)\n",
    "img_cnn = kernel(kernels[..., 0], img)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "fig.suptitle('Source vs CNN')\n",
    "ax1.imshow(img, cmap='gray_r')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(img_cnn, cmap='gray_r')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layers[0].get_weights()[0].shape[-1] # 總共次數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我們有四種圖樣 plt.subplots\n",
    "kernels = model.layers[0].get_weights()[0]\n",
    "img = X_train[0].reshape(28, 28)\n",
    "for k in range(model.layers[0].get_weights()[0].shape[-1]): \n",
    "    img_cnn = kernel(kernels[..., k], img)\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(4/3,4/3))\n",
    "    fig.suptitle('Source vs CNN {}'.format(k) )\n",
    "    ax1.imshow(img, cmap='gray_r')\n",
    "    ax1.axis('off')    \n",
    "    ax2.imshow(img_cnn, cmap='gray_r')\n",
    "    ax2.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
