{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CNTK backend\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU\n"
     ]
    }
   ],
   "source": [
    "# 如何知道有多少數據 Shift + Enter , Ctrl + Enter\n",
    "from keras import datasets\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#print(dir(datasets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "#print(dir(mnist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 數據是28 * 28 = 784\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFkAAABYCAYAAACeV1sKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAA/BJREFUeJzt2zssNG0YxvH/OB9iFx2ilmgcQhQSx4QKvUKoSBwaIpItlBI6h26jEhqxhYaQUIhEFMQhoZCIKGgECQWxvsL3mLz72s/7LXOP2ff+NYrZmXn2yuXJHJ61Xl9fUc5KcHsAfwMNWYCGLEBDFqAhC9CQBWjIAjRkAUnC54vnOx8r2gZtsgANWYCGLEBDFqAhC9CQBWjIAjRkARqyAOk7Pke9vLwAcHd399u26elpAB4fHwE4PT0FYGZmBoChoSEAFhYWAEhLSwNgZGQEgNHR0ZjHpU0W4KkmX1xcAPD09ATA9vY2AFtbWwDc3t4CsLi4+OmxCgsLAejv7wcgFAoBkJWVBUBJSQkAtbW1Xx63NlmAJbwkIKaT7e3tAdDQ0AB8POf+qcTERABmZ2cByMzM/GV7fn4+ADk5OQAUFRX96aH1KZybPNHkm5sbAKqqqgA4Ozv7dB/zWdPIjY0NAFJSUoCv/TdEoU12kyeuLnJzcwGYmJgAYHl5GYCysjIABgYGfvl8aWkp6+vrgD3nHh0dATA5Oen8gCNokwV4Yk6OdH9/D9jXtN3d3QAEg0EA5ubmaG9v/45T/R86J7vJkyH7fD58Ph+WZWFZFn6/H7/f/749GAwSDocJh8MujtLmyZC9xpNzcqSHhwcAWlpaANjc3GRlZQWApqYmJ075EZ2T3RQXTTbMnWB5eTnZ2dkA1NfXA1BRUQFAb28vAJYVtXixinrAuArZCIVCdHV1AfblnjE2NgZAR0cHAHl5ed91Wp0u3BSXTQY4PDwEYHBwEOD9Ntvo6ekBIBAIAFBQUPDVU2qT3RS3TTbMKynzUKmzs/NtIP9+78bGRgDW1ta+eiptspvivsmRUlNTAXh+fgYgOTkZgNXVVQDq6upiPbQ22U2eeGgfi4ODA8BeHrC7uwvYDTaKi4sBqKmpcWws2mQBcdVks/RqamqKpaUlAK6urj78bFLS21c3d3wJCc71TZsswNNNNi2dn58H7EWF5+fnUfeprKwE7Du91tZWB0f4RpsswFNNvr6+BuD4+BiAvr4+AE5OTqLuYxa5DA8PA9DW1gY4OwdH0iYL+NFNNsuzzCv//f194PNlWtXV1e9P35qbmwFIT093apif0iYL+FFN3tnZAWB8fByw79IuLy//c7+MjAzAXq4VCAR+WxLrJm2ygB/VZPOTAvM3knnOYF79mwXd5kc15uXpT6NNFvDXPU92kD5PdpOGLEBDFqAhC9CQBUhfJ3/7Kj8v0CYL0JAFaMgCNGQBGrIADVmAhixAQxagIQvQkAVoyAI0ZAEasgANWYCGLEBDFqAhC9CQBWjIAjRkARqyAA1ZgIYs4B9cUAeqd7SI5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 畫一張\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(X_train[0], cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "# data pre-processing MLP , not for CNN\n",
    "X_train, X_test = X_train.astype(np.float32).reshape(60000, 28, 28, 1)/255.0, \\\n",
    "                  X_test.astype(np.float32).reshape(10000, 28, 28, 1)/255.0\n",
    "# one_hot encoding\n",
    "y_train_oh, y_test_oh = to_categorical(y_train), to_categorical(y_test) \n",
    "\n",
    "print(X_train.shape , X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 9,098\n",
      "Trainable params: 9,098\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# build model\n",
    "# keras.layers.Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', activation=None)\n",
    "# filters 幾種新的圖框 來描述圖片的邊界效果\n",
    "# kernel_size 掃描整個原圖過程中要使用的計算大小，搭配kernel_weight取出邊界\n",
    "# strides 確保新的圖框 大小是否跟原圖一樣大 因素之一，掃描的每一次往左右下上的推進大小\n",
    "# padding 確保新的圖框 大小是否跟原圖一樣大 因素之二，掃描的要不要針對邊框加上多一格的數據\n",
    "# input_shape 因為針對圖片進行作業 所以要指定row * col * RGB <--\"image_data_format\": \"channels_last\"\n",
    "# https://i.stack.imgur.com/9OZKF.gif 看圖\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D\n",
    "from keras import optimizers\n",
    "model = Sequential()\n",
    "\n",
    "model.add( Conv2D(filters=8, kernel_size=(3,3), strides=(1, 1), \n",
    "                  padding='same', activation='relu', input_shape=(28, 28, 1)  ))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add( Conv2D(filters=16, kernel_size=(3,3), strides=(1, 1), \n",
    "                  padding='same', activation='relu' )) #(8 * (3, 3) + 1 ) * 16 = 1168\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add( Flatten()) # 將上述的新產生的filters=四種圖框 攤平\n",
    "#model.add( Dense(units=1000, activation='relu' ) )\n",
    "#model.add( Dense(units=500, activation='relu') )\n",
    "model.add( Dense(units=10, activation='softmax') )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model \n",
    "# ValueError: Error when checking target: expected dense_3 to have 2 dimensions\n",
    "# but got array with shape (60000, 10, 2, 2)\n",
    "# ValueError: Error when checking target: expected dense_6 to have shape (10,) but got array with shape (1,)\n",
    "# 54000/54000 [==============================] - 89s 2ms/step - \n",
    "# loss: 0.3113 - acc: 0.9134 - val_loss: 0.1181 - val_acc: 0.9660\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(0.0001), loss='categorical_crossentropy', metrics=['accuracy'] )\n",
    "history = model.fit(X_train, y_train_oh, validation_split=0.1, epochs=10, verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keras 2.2.* : acc \n",
    "#keras 2.3.* : accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.title('Accuracy of Keras')\n",
    "plt.plot(history.history['acc'], color='blue')\n",
    "plt.plot(history.history['val_acc'], color='red')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.title('Loss of Keras')\n",
    "plt.plot(history.history['loss'], color='blue')\n",
    "plt.plot(history.history['val_loss'], color='red')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model \n",
    "print(model.evaluate(X_train, y_train_oh), model.evaluate(X_test, y_test_oh) )\n",
    "# predict model \n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 \n",
    "# 請你找一下那些數字是錯誤 slicing \n",
    "index_error = np.argmax(y_pred, axis=1) != np.argmax(y_test_oh, axis=1)\n",
    "\n",
    "X_error      =  X_test[ index_error ]\n",
    "y_error      =  y_test_oh[ index_error ]\n",
    "y_error_pred =  y_pred[ index_error ]\n",
    "\n",
    "print('Total error amount is {}'.format(X_error.shape[0]))\n",
    "\n",
    "# Plot for top 10 [:10]\n",
    "for i in range(10):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.title('GT:{} --> Pred:{}'.format(np.argmax(y_error[i]), np.argmax(y_error_pred[i])) )\n",
    "    plt.imshow(X_error[i].reshape(28,28), cmap='gray' )\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
